<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>EyeMove Technologies</title>
  <link rel="canonical" href="blog.html" />

  <!-- Behavioral Meta Data -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  <!-- Core Meta Data -->
  <meta name="author" content="EyeMove">
  <meta name="description" content="EyeMove Technologies. We seek to enable the mobility of quadraplegic patients at the blink of an eye.">
  <meta name="keywords" content="mechatronics,software,engineer,developer,html5,css3,javascript,python,design,java,c++,robotics,wheelchair,medical,devices,als,quadreplegic">

  <!-- Open Graph Meta Data -->
  <meta property="og:title" content="EyeMove Technologies">
  <meta property="og:type" content="website">
  <meta property="og:image" content="https://eyemove.tech/img/thumbnail.png">
  <meta property="og:url" content="https://eyemove.tech">
  <meta property="og:description" content="EyeMove Technologies. We seek to enable the mobility of quadraplegic patients at the blink of an eye.">

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="img/icons/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="img/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="img/icons/favicon-16x16.png">
  <link rel="manifest" href="img/icons/manifest.json">
  <link rel="mask-icon" href="img/icons/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="img/icons/favicon.ico">
  <meta name="msapplication-config" content="/img/icons/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">

  <!-- Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111259808-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-111259808-1');
  </script> -->

  <!-- Preload CSS -->
  <style type="text/css">
    .preloader,.progress,nav,section{display:block}@font-face{font-family:Montserrat;font-style:normal;font-weight:400;src:local('Montserrat-Regular'),url(https://fonts.gstatic.com/s/montserrat/v7/zhcz-_WihjSQC0oHJ9TCYC3USBnSvpkopQaUR-2r7iU.ttf) format('truetype')}@font-face{font-family:Montserrat;font-style:normal;font-weight:700;src:local('Montserrat-Bold'),url(https://fonts.gstatic.com/s/montserrat/v7/IQHow_FEYlDC4Gzy_m8fcvEr6Hm6RMS0v1dtXsGir4g.ttf) format('truetype')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;src:local('Open Sans Light'),local('OpenSans-Light'),url(https://fonts.gstatic.com/s/opensans/v13/DXI1ORHCpsQm3Vp6mXoaTYnF5uFdDttMLvmWuJdhhgs.ttf) format('truetype')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;src:local('Open Sans'),local('OpenSans'),url(https://fonts.gstatic.com/s/opensans/v13/cJZKeOuBrn4kERxqtaUH3aCWcynf_cDxXwCLxiixG1c.ttf) format('truetype')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;src:local('Open Sans Bold'),local('OpenSans-Bold'),url(https://fonts.gstatic.com/s/opensans/v13/k3k702ZOKiLJc3WVjuplzInF5uFdDttMLvmWuJdhhgs.ttf) format('truetype')}.clear{clear:both}.main-title ul{list-style:none}#navbar li a,.main-title a,.scrollup{text-decoration:none}html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;color:#222}a{background-color:transparent}.text-outline{text-shadow:1px 1px 3px #000,1px -1px 3px #000,-1px 1px 3px #000,-1px -1px 3px #000}.preloader{position:fixed;width:100%;height:100%;z-index:9999;background:#fff;text-align:center}.loading,.progress{width:100px;position:absolute;overflow:hidden}.loading{top:50%;margin-top:-12px;left:50%;margin-left:-50px;height:24px}.progress{bottom:0;height:1px;left:-102px;background-color:#00d9ec;-webkit-animation:loader-anim 1s 0s infinite cubic-bezier(.785,.135,.15,.86);animation:loader-anim 1s 0s infinite cubic-bezier(.785,.135,.15,.86)}h3{margin:0;font-family:Montserrat,arial,sans-serif;font-size:14px;font-weight:700;line-height:1em;letter-spacing:.2em;color:#161a1b}@-webkit-keyframes loader-anim{0%{left:-102px}100%{left:102px}}@keyframes loader-anim{0%{left:-102px}100%{left:102px}}body{font-size:1em;line-height:1.4}body:after{display:none;content:url(img/check.png)}#home div,.video-mask,body,html{width:100%;height:100%}body,html{padding:0;background:#000;margin:0}.jump-menu{display:none;position:absolute;top:0;right:0}#home div,.main-title ul{position:relative}.main-title,.video-mask,.video-volume{position:absolute}.video-mask{top:0;left:0;z-index:-10;background-color:#000}.video-volume{bottom:80px;margin-left:-12px;left:50%;width:25px;height:25px;background:url(img/audio-mute.png) no-repeat}.bouncing-arrow{margin-left:-16px;left:50%;background:url(img/arrow-down.png) no-repeat;-webkit-animation:bounce 1s infinite;animation:bounce 1s infinite;width:32px!important;height:32px!important}@-webkit-keyframes bounce{0%{bottom:45px}25%,75%{bottom:55px}50%{bottom:60px}100%{bottom:40px}}.welcome{text-transform:none;font-size:26px;letter-spacing:3px}#home{height:100%}.main-title .second-title{font-size:16px;font-weight:400;font-family:'Open Sans',sans-serif!important;width:680px;text-transform:none;margin:auto}.continue-button{width:135px;margin:40px auto 0;color:#fff;font-size:14px;font-weight:700;font-family:'Open Sans',sans-serif;padding:11px 25px;border:2px solid rgb(0,130,255);border-radius:10px;letter-spacing:2px}.main-title{color:#fff;height:385px;overflow:hidden;top:50%;margin-top:-176px;width:100%;text-align:center;z-index:10}.main-title .spacer{width:60px;margin:30px auto 40px}.title-container{width:90%;margin:0 auto}.main-title ul{font-weight:300;text-align:center;padding:0;margin:10px 0 0;height:100px;font-size:100px;font-family:"Brandon Grot W01 Bold",Montserrat,sans-serif,"Helvetica Neue",Helvetica,Arial;letter-spacing:5px;z-index:100}#navbar,.scrollup{font-family:'Open Sans',sans-serif}.main-title ul li{width:100%;text-align:center;position:absolute;opacity:0;top:40px;line-height:100px}.main-title li.current-title{opacity:1;top:0}.spacer{width:100px;height:2px;margin:auto}#navbar,#navbar>a,.scrollup{display:none}.scrollup{z-index:500;width:50px;height:50px;border-radius:50%;opacity:.8;position:fixed;bottom:50px;right:40px;background:rgb(0,130,255);color:#fff;line-height:55px;font-size:25px;text-align:center}#navbar li{position:relative}#navbar{width:60em;font-weight:400;position:absolute;top:25%;left:50%;margin-left:-30em}#navbar li a{color:#999;display:block}#navbar>ul{height:3.75em;background-color:#f5f5f5;padding:0}#navbar>ul>li{width:25%;height:100%;float:left}#navbar>ul>li>a{height:100%;font-size:1.5em;line-height:2.5em;text-align:center}#navbar>ul>li:not(:last-child)>a{border-right:1px solid rgb(0,130,255)}@media only screen and (max-width:62.5em){#navbar{width:100%;margin:0}}#mobile-background{height:100%;display:none;background-size:cover}.green .spacer{background:rgb(0,130,255)}@media only screen and (min-width:976px) and (max-width:1280px){.main-title ul{font-size:70px}.main-title{font-size:60px;height:352px;top:50%;margin-top:-176px}.main-title .spacer{margin:5px auto 25px}}@media only screen and (max-width:975px){#navbar,html{font-size:75%}#navbar,#navbar>a{position:relative}#navbar,#navbar:not(:target)>a:first-of-type,.jump-menu{display:block}.main-title{height:350px;top:50%;margin-top:-175px}.continue-button{margin-top:15px}#navbar{top:auto;left:auto}#navbar>a{width:50px;height:75px;text-align:left;text-indent:-9999px;background:url(img/menu-icon-blk.png) no-repeat rgba(0,0,0,0);float:right}#navbar>ul{height:auto;display:none;position:absolute;left:0;right:0;margin-top:75px}#navbar>ul>li{width:100%;float:none}#navbar>ul>li>a{height:auto;padding:0 .833em;border-right:none;border-bottom:1px dotted rgb(0,130,255)}}@media only screen and (min-width:796px) and (max-width:974px){.main-title ul{font-size:60px}.main-title{font-size:50px}.main-title span{top:100px}}@media only screen and (max-width:795px){.main-title ul{margin-top:0;height:80px;font-size:35px}.main-title .spacer{margin:20px auto}}@media only screen and (min-width:480px) and (max-width:795px){.main-title .second-title{width:345px}.main-title{font-size:25px}.main-title span{top:70px}}@media only screen and (max-width:479px){.main-title ul li{line-height:50px}.main-title .second-title{font-size:14px;width:90%}.main-title{height:300px;top:50%;margin-top:-150px;font-size:30px}.welcome{font-size:13px}.main-title span{top:100px}.scrollup{display:none!important}.bouncing-arrow{display:none}}@media only screen and (max-height:600px){.video-volume{bottom:50px}}@media only screen and (max-height:500px){.video-volume{bottom:10px}.bouncing-arrow{display:none}}
  </style>
</head>

<body class="green">
  <div class="preloader">
    <div class="loading">
      <h3>LOADING...</h3>
      <span class="progress"></span>
    </div>
  </div>
  <header class="header">
    <a href="blog.html#blog">
      <div class="logo">
        <!-- <span><span></span></span>EYEMOVE -->
        <img src="img/icons/favicon-32x32.png" alt="Image not found. Please try reloading.">EYEMOVE
      </div>
    </a>
    <nav id="navbar">
      <a class="jump-menu"></a>
      <ul id="mobile-nav">
        <li class="mobile-current"><a href="index.html">HOME</a></li>
        <li><a href="blog.html#blog">BLOG</a></li>
        <li><a href="blog.html#contact">CONTACT</a></li>
      </ul>
    </nav>
    <nav class="menu">
      <ul id="nav">
        <li class="current"><a href="index.html">HOME</a></li>
        <li><a href="blog.html#blog">BLOG</a></li>
        <li><a href="blog.html#contact">CONTACT</a></li>
      </ul>
    </nav>
  </header>

  <article id="blog" class="content dark">
    <header class="title one hideme fade">BLOG</header>
    <div class="spacer"></div>
    <div class="title two hideme fade">Check out our progress!</div>
    <div id="work" class="work-container">
      <div id="update-03" class="work-exp hideme">
        <div class="tag-project">UPDATE 3</div>
        <div class="title-project">EMBEDDED and ELECTRICAL INTERFACE</div>
        <div class="project-date">FEB 20, 2021</div>
        <div class="author">By: Arjun Narayan</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>
            Now that we had a wheelchair, we needed a way to drive it without user input. 
            All powered wheelchairs came with joysticks, but we needed some expandable interface we could integrate with our NVIDIA Jetson compute platform.
            We reached out to a Chief Engineer at Quantum who has been extremely helpful in our process.
            He pointed us to the right technical documentation, hardware, and necessary firmware upgrades.
            In short, the wheelchair uses a proprietary CAN-based system internally to communicate between the base and other devices.
            However, there are external devices we can utilize that expose a DB9 interface we can use with analog voltage signals, much easier than CAN.
            This was the avenue we decided to pursue.
            The DB9 interface is shown here:
          </p>
          <p class="blog-photo-section">
            <img class="blog-photo" src="img/blog/interface.png" alt="Image not found. Please try reloading.">
          </p>
          <p>
            Pin 3 (center) expects the "neutral" voltage, which is half of the power voltage (12V), so 6V. 
            This is the voltage at which the wheelchair will be at stand-still.
            By increasing the voltage slightly (&#60; 2V) on Pins 1 & 2, a proportional change in the wheelchair's forward speed & angular speed (direction) will be applied.
            We found in other sources that the 2 power pins (7 & 9) must be shorted together, and also that Pin 8 acts as the ground for any external device.
            All other pins can remain untouched.
            Of the potential devices we attempted integrating with the wheelchair, the Quantum QLogic Enhanced Display worked the best for interfacing over DB9.
            Thus, our embedded interface looks like the following:
          </p>
          <p class="blog-photo-section">
            <!-- <img width="500" height="250" src="img/blog/embedded-interface.png" alt="Image not found. Please try reloading."> -->
            <img class="blog-photo-sensor" src="img/blog/embedded-interface.png" alt="Image not found. Please try reloading.">
          </p>
          <p>
            We initially planned on passing analog voltages directly from our Xavier to the DB9 interface.
            However, this did not work as planned for several reasons.
            Primarily, none of our on-hand devices could output analog voltages, only PWMs at best.
            We also did not have easy access to a small DAC for conversion.
            Also, the voltages expected by the wheelchair were in the 4-8V range, and so could not be supplied by a 5V microcontroller directly.
            This all means some light signal processing is needed.
          </p>
          <br>
          <p>
            To begin, we originally expected to output these PWMs from the Xavier.
            However, Jetpack requires the hardware PWM peripherals to be configured before flashing.
            This would require us to recongifure them & reflash the device, which would erase several weeks of work carefully setting up the 
            ML environment and dependencies, and so using an Arduino as a middle-man was an easier alternative.
            The Jetson and Arduino talk over a USB serial connection with the downstream packets containing a "mock" value of the X & Y joystick deflections.
          </p>
          <br>
          <p>
            To solve the first problem, a basic passive RC filter can be used to convert the PWM to an analog voltage between 0 - 5V. 
            The Arduino can output PWMs (using hardware) at 62.5kHz. We referenced several articles for selecting component values, such as these: <br/>
            <br>
            <a href="https://www.analog.com/en/technical-articles/accurate-fast-settling-analog-voltages-from-digital-pwm-signals.html#">Accurate Fast Settling Analog Voltages from Digitial PWM Signals</a><br/>
            <br>
            <a href="http://ww1.microchip.com/downloads/en/Appnotes/90003250A.pdf">Using PWM to Generate an Analog Output</a><br/>
            <br>
            After the PWM is now an analog voltage, it must be scaled to fit inside a 4-8V range.
            This is done with a simple non-inverting opamp amplifier that amplifies 2x the input signal.
            The final step is to ensure the incoming PWM signals are bounded to between 4-8V, which is easily done in the Arduino software.
            The final circuit diagram looks like so:
          </p>
          <p class="blog-photo-section">
            <img class="blog-photo-sensor" src="img/blog/fydp_circuit.png" alt="Image not found. Please try reloading.">
          </p>
          The Enhanced Display (shown on the left) requires the "neutral" voltage to be the center of the power voltage, which is 12V.
          This is the purpose of the voltage divider on the left, with a voltage buffer going to Pin 3 (center reference). 
          Pins 1 & 2 are then used for controlling speed & direction of the wheelchair. 
          The final extra addition to the signal processing was an extra 10uF filter capacitor to remove any excess ripple or noise.
          Below is our initial breadboard mock-up of this circuit, and our final protoboard version:
        <p class="blog-photo-section">
          <img class="blog-photo" src="img/blog/breadboard.jpg" alt="Image not found. Please try reloading.">
          <img class="blog-photo" src="img/blog/protoboard_good_top.jpg" alt="Image not found. Please try reloading.">
          <img class="blog-photo" src="img/blog/protoboard_good_back.jpg" alt="Image not found. Please try reloading.">
        </p>
        <br>
        <p>
          This circuit worked well-enough for our purposes, but there definetly are improvements to be made.
          For instance, there is no easy hardware kill-switch currently. 
          If the Arduino were to fail and create irrational PWM outputs, there is no easy way to disconnect the hardware components without turning off the chair entirely.
        </p>
        <br>
        <p>
          Now that Electrical is done, we can dive into the low-level embedded interface. 
          Later posts will deal more with the pure software aspect of embedded, as well as with the motion controls.
          Now, the Arduino can only output a PWM at a 0-255 resolution, so our downstream message to the Arduino will be 1 byte each for the speed & direction values.
          The Arduino code will listen on the serial port for a package containing 2 bytes, or else will bring the wheelchair speed back to 0.
          The wheelchair base already has a velocity controller that handles the speed ramp up and down for us, and so this is not a concern.
          In terms of user control, we initially tested the setup by creating a small teleop interface using the keyboard.
          This lets us control the speed & direction magnitudes with the arrow keys, and enable us to sanity check everything worked together.
          The final step in testing was to mount the wheelchair up on cinderblocks.
          This allowed us to spin the wheels freely for testing without having the wheelchair run off on us (which it did once).
          Below is an early test video showcasing the initial breadboard setup and the resulting motion:
        </p>
        <p class="blog-video-section">
          <iframe width="640" height="480"
            src="https://www.youtube.com/embed/nyDg6v5E0uU">
          </iframe>
        </p>
        <p>
          This progress greatly enables the rest of the team to test on the wheelchair platform, and still has some work in cleanup and optimization to do.
          Stay tuned for much more!
        </p>
        </div>
      </div> 
      <div id="update-02" class="work-exp hideme">
        <div class="tag-project">UPDATE 2</div>
        <div class="title-project">SYSTEM ARCHITECTURE</div>
        <div class="project-date">JAN 20, 2020</div>
        <div class="author">By: Arjun Narayan</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>The Problem</h2>
          <p>
            Our goal is to enable powered wheelchair users to navigate with only their eyes. 
            Without use of joysticks, head tilt, sip and puff, or other existing solutions that come with a laundry list of potential issues.
            In order to do this, we have 3 main problems to solve:
          </p>
          <h3>&nbsp;&nbsp;&nbsp;&nbsp;1. Accurately Detect Eye Gaze</h3><br>
          <h3>&nbsp;&nbsp;&nbsp;&nbsp;2. Convert to Real-World Position</h3><br>
          <h3>&nbsp;&nbsp;&nbsp;&nbsp;3. Send Motion Commands to Wheelchair</h3><br>
          <p>
            The individual solution to these 3 problems will be the subject of the remainder of the blog posts on this site. 
          </p>
          <h2> Initial Hardware Summary </h2>
          <p>
            The eye tracking solution will make use of a simple common RGB cameras and a Machine Learning / Computer Vision based approach. 
            In order to navigate it's environment and provide necessary safety for the user, the wheelchair will make use of modern autonomy solutions such as depth and tracking cameras.
            This is illustrated below, with the eye tracking example curtisy of <a href="https://antoinelame.fr/en/gazetracking">Antoine Lamé</a>.
          </p>
          <h2>Basic Illustration</h2>
          <p class="blog-photo-section">
            <img class="blog-photo" src="img/blog/wheelchair_basic.png" alt="Image not found. Please try reloading.">
          </p>
          <h2>Eye Tracking Example</h2>
          <p class="blog-photo-section">
            <img class="blog-photo" src="img/blog/antoine.gif" alt="Image not found. Please try reloading.">
          </p>

          <h2> Compute Selection </h2>
          To begin our hardware summary, we focused on our compute hardware selection.
          The main requirement early on was something with enough raw AI computational power to support the simulatnous gaze tracking and autonomy stack.
          We immediately began researching the NVIDIA Jetson line and focused on the Xavier and Nano devices.
          Since we would be likely running 2 separate computationally intensive pipelines, the computational power was our main concern over power draw or size.
          Thus, we went with the <a href="https://developer.nvidia.com/embedded/jetson-agx-xavier-developer-kit">NVIDIA Xavier AGX</a>.
          Since these platforms are meant to be general purpose, they are great for this early stage while we iron out exactly what our pipelines will look like and exactly how much power we need.

          <p class="blog-photo-section">
            <img class="blog-photo" src="img/blog/xavier.jpg" alt="Image not found. Please try reloading.">
          </p>

          The Xavier runs Jetpack 4.4, an NVIDIA custom distro of Ubuntu 18. 
          This drove our choice to use <a href="https://www.ros.org/">Robot Operating System (ROS)</a> as our middle-ware since it easily supports Ubuntu-based systems.
          This will allow us to easily prototype our various software systems separately, and easily integrate them later during testing.
          <br>
          <br>
          <h2> Sensor Selection </h2>
          For our sensors we wanted devices that had easy open-source drivers that we could use, and that had sufficiently strong specifications.
          For autonomy we went with the Intel Realsense line because of their <a href="https://github.com/IntelRealSense/realsense-ros">existing driver libraries</a>, and many good thing we have seen others build with them.
          We opted for a depth camera to be used to obstacle avoidance and easy navigation, and a tracking camera for easy closed loop motion control at all levels.
          For gaze tracking we wanted an RGB camera that was cheap, common enough to purchase, and could operate fast enough. 
          After some research we discovered the common V4L2 (Video for Linux 2) camera interface, and an <a href="https://github.com/ros-drivers/usb_cam">open source ROS driver for it too</a>.
          More research shows us the Logitech C920 HD camera that can do 720p at 60 fps, which was more than enough for our needs. 
          The selection summary is shown below:

          <p class="blog-photo-section">
            <!-- <img width="700" height="350" src="img/blog/sensor_selection.png" alt="Image not found. Please try reloading."> -->
            <img class="blog-photo-sensor" src="img/blog/sensor_selection.png" alt="Image not found. Please try reloading.">
          </p>


        </div>
    </div>
      <div id="update-01" class="work-exp hideme">
        <div class="tag-project">UPDATE 1</div>
        <div class="title-project">WHEELCHAIR ACQUIRED</div>
        <div class="project-date">NOV 30, 2020</div>
        <div class="author">By: Ali Toyserkani</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>
            In order to get the project started, we needed to purchase a wheelchair that we will be able to prototype on. 
            We chose a Quantum Q6 Edge HD powered chair as it was the best in terms of value, features, and extensibility. 
            As an added benefit we are receiving engineering help from a contact at Quantum.
            The wheelchair operates with 2 12V car batteries, which powers an internal AAM (Advanced Actuator Module) which control the motors.  
          </p>
          <h2>Photos</h2>
          <p class="blog-photo-section">
            <img class="blog-photo" src="img/blog/quantum-wheelchair.png" alt="Image not found. Please try reloading.">
            <img class="blog-photo" src="img/blog/ali-saeejith-wheelchair.jpg" alt="Image not found. Please try reloading.">
          </p>
        </div>
      </div>

  
      
    </div>
  </article>

  <footer class="footer light">
    <div class="footer-container">
      <!-- <div id="contact" class="title one hideme fade">CONTACT US</div>
      <div class="spacer"></div>
      <div class="title two hideme fade">Feel free to reach out to us!</div>
      <form action="https://formspree.io/eyemovetechnologies@gmail.com" class="contactForm" method="post">
        <div class="bay form-horizontal">
          <div class="form-section">
            <input class="span9" type="text" name="name" placeholder="FULL NAME">
          </div>
          <div class="form-section">
            <input class="span9" type="text" name="email" placeholder="YOUR EMAIL">
          </div>
          <div class="form-section">
            <textarea class="span9" name="message" rows="12" placeholder="TYPE MESSAGE"></textarea>
          </div>
          <div class="form-section">
            <button type="submit" class="contour-btn green">SEND MESSAGE</button>
          </div>
        </div>
      </form> -->
      <div class="contact">
        <ul class="icons hideme fade">
          <!-- <li><a class="facebook" href="https://www.facebook.com/eyemovetechnologies/" target="_blank"></a></li>
          <li><a class="youtube" href="https://www.youtube.com/channel/" target="_blank"></a></li> -->
        </ul>
        <div class="copy-right hideme fade">© 2021 EyeMove Technologies. All rights reserved.</div>
      </div>
    </div>
  </footer>

  <a href="blog.html#blog" class="scrollup">^</a>

  <!-- CSS -->
  <link rel="preload" href="css/dist/home.min.css" as="style" onload="this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="css/dist/home.min.css"></noscript>
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Montserrat:400,700" as="style" onload="this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700"></noscript>
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" as="style" onload="this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700"></noscript>
  <script>!function(e){"use strict";var t=function(t,n,r){function o(e){return i.body?e():void setTimeout(function(){o(e)})}function a(){d.addEventListener&&d.removeEventListener("load",a),d.media=r||"all"}var l,i=e.document,d=i.createElement("link");if(n)l=n;else{var s=(i.body||i.getElementsByTagName("head")[0]).childNodes;l=s[s.length-1]}var u=i.styleSheets;d.rel="stylesheet",d.href=t,d.media="only x",o(function(){l.parentNode.insertBefore(d,n?l:l.nextSibling)});var f=function(e){for(var t=d.href,n=u.length;n--;)if(u[n].href===t)return e();setTimeout(function(){f(e)})};return d.addEventListener&&d.addEventListener("load",a),d.onloadcssdefined=f,f(a),d};"undefined"!=typeof exports?exports.loadCSS=t:e.loadCSS=t}("undefined"!=typeof global?global:this),function(e){if(e.loadCSS){var t=loadCSS.relpreload={};if(t.support=function(){try{return e.document.createElement("link").relList.supports("preload")}catch(e){return!1}},t.poly=function(){for(var t=e.document.getElementsByTagName("link"),n=0;n<t.length;n++){var r=t[n];"preload"===r.rel&&"style"===r.getAttribute("as")&&(e.loadCSS(r.href,r),r.rel=null)}},!t.support()){t.poly();var n=e.setInterval(t.poly,300);e.addEventListener&&e.addEventListener("load",function(){e.clearInterval(n)}),e.attachEvent&&e.attachEvent("onload",function(){e.clearInterval(n)})}}}(this);</script>

  <!-- JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script defer src="js/dist/blog.min.js"></script>
</body>
</html>
